{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train Phase transformations\n",
    "# train_transforms = transforms.Compose([\n",
    "#                                       #  transforms.Resize((28, 28)),\n",
    "#                                       #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
    "#                                        transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
    "#                                        transforms.RandomHorizontalFlip(),\n",
    "#                                        transforms.RandomRotation(15),\n",
    "#                                        transforms.ToTensor(),\n",
    "#                                        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values. \n",
    "#                                        # Note the difference between (0.1307) and (0.1307,)\n",
    "#                                        ])\n",
    "\n",
    "# # Test Phase transformations\n",
    "# test_transforms = transforms.Compose([\n",
    "#                                       #  transforms.Resize((28, 28)),\n",
    "#                                       #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
    "#                                        transforms.ToTensor(),\n",
    "#                                        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "#                                        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = [0.4914, 0.4822, 0.4465]\n",
    "stds = [0.2470, 0.2435, 0.2616]\n",
    "\n",
    "train_transforms = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=means, std=stds, always_apply=True),\n",
    "        A.PadIfNeeded(min_height=40, min_width=40, always_apply=True),\n",
    "        A.RandomCrop(height=32, width=32, always_apply=True),\n",
    "        A.HorizontalFlip(),\n",
    "        A.CoarseDropout(max_holes=1, max_height=8, max_width=8, min_holes=1, min_height=8, min_width=8, fill_value=means),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transforms = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=means, std=stds, always_apply=True),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar10SearchDataset(datasets.CIFAR10):\n",
    "\n",
    "    def __init__(self, root=\"~/data\", train=True, download=True, transform=None):\n",
    "\n",
    "        super().__init__(root=root, train=train, download=download, transform=transform)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image, label = self.data[index], self.targets[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "\n",
    "            transformed = self.transform(image=image)\n",
    "\n",
    "            image = transformed[\"image\"]\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train = Cifar10SearchDataset(root='./data', train=True,\n",
    "                                        download=True, transform=train_transforms)\n",
    "test = Cifar10SearchDataset(root='./data', train=False,\n",
    "                                       download=True, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available? True\n"
     ]
    }
   ],
   "source": [
    "SEED = 1\n",
    "\n",
    "# CUDA?\n",
    "cuda = torch.cuda.is_available()\n",
    "print(\"CUDA Available?\", cuda)\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# dataloader arguments - something you'll fetch these from cmdprmt\n",
    "dataloader_args = dict(shuffle=True, batch_size=512, num_workers=0, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
    "\n",
    "# train dataloader\n",
    "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
    "\n",
    "# test dataloader\n",
    "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ship  bird  cat   dog  \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "import torchvision\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[:4]))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "dropout_value = 0.1\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # CONVOLUTION BLOCK 1 input 32/1/1\n",
    "        self.convblock1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, groups = 3, out_channels=3, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(1, 1), padding=0, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 32/3/1\n",
    "\n",
    "        \n",
    "        self.convblock2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, groups=32, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1, 1), padding=0, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 32/5/1\n",
    "\n",
    "        # TRANSITION BLOCK 1\n",
    "        self.convblock3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=64, \n",
    "                out_channels=32, \n",
    "                kernel_size=(3,3), \n",
    "                padding=2, \n",
    "                stride=2, \n",
    "                dilation=2, \n",
    "                bias=False),\n",
    "        ) # output_size = 16/7/2\n",
    "\n",
    "        # CONVOLUTION BLOCK 2\n",
    "        self.convblock4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, groups=32, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1, 1), padding=0, bias=False),\n",
    "            nn.ReLU(),            \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 16/11/2\n",
    "\n",
    "        self.convblock5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, groups=64, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(1, 1), padding=0, bias=False),\n",
    "            nn.ReLU(),            \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 16/15/2\n",
    "\n",
    "        # TRANSITION BLOCK 2\n",
    "        self.convblock6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, \n",
    "                      out_channels=32, \n",
    "                      kernel_size=(3,3), \n",
    "                      padding=2, \n",
    "                      dilation=2,\n",
    "                      stride=2, \n",
    "                      bias=False),\n",
    "        ) # output_size = 8/19/4\n",
    "\n",
    "        self.convblock7 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, groups=32, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1, 1), padding=0, bias=False),\n",
    "            nn.ReLU(),            \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 8/24/4\n",
    "        self.convblock8 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, groups = 64, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(1, 1), padding=0, bias=False),\n",
    "            nn.ReLU(),            \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 8/32/4\n",
    "\n",
    "        self.convblock9 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, groups=64,  out_channels=64, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(1, 1), padding=0, bias=False),\n",
    "            nn.ReLU(),            \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 6/40/4\n",
    "        \n",
    "        # OUTPUT BLOCK\n",
    "        self.gap = nn.Sequential(\n",
    "            nn.AvgPool2d(kernel_size=6)\n",
    "        ) # output_size = 1/64\n",
    "\n",
    "        self.convblock10 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n",
    "            # nn.BatchNorm2d(10),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(dropout_value)\n",
    "        ) \n",
    "\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_value)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convblock1(x)\n",
    "        x = self.convblock2(x)\n",
    "        x = self.convblock3(x)\n",
    "        x = self.convblock4(x)\n",
    "        x = self.convblock5(x)\n",
    "        x = self.convblock6(x)\n",
    "        x = self.convblock7(x)\n",
    "        x = self.convblock8(x)\n",
    "        x = self.convblock9(x)\n",
    "        x = self.gap(x)        \n",
    "        x = self.convblock10(x)\n",
    "\n",
    "        x = x.view(-1, 10)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in i:\\installs\\lib\\site-packages (1.5.1)\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the 'I:\\Installs\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 3, 32, 32]              27\n",
      "            Conv2d-2           [-1, 32, 32, 32]              96\n",
      "              ReLU-3           [-1, 32, 32, 32]               0\n",
      "       BatchNorm2d-4           [-1, 32, 32, 32]              64\n",
      "           Dropout-5           [-1, 32, 32, 32]               0\n",
      "            Conv2d-6           [-1, 32, 32, 32]             288\n",
      "            Conv2d-7           [-1, 64, 32, 32]           2,048\n",
      "              ReLU-8           [-1, 64, 32, 32]               0\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "          Dropout-10           [-1, 64, 32, 32]               0\n",
      "           Conv2d-11           [-1, 32, 16, 16]          18,432\n",
      "           Conv2d-12           [-1, 32, 16, 16]             288\n",
      "           Conv2d-13           [-1, 64, 16, 16]           2,048\n",
      "             ReLU-14           [-1, 64, 16, 16]               0\n",
      "      BatchNorm2d-15           [-1, 64, 16, 16]             128\n",
      "          Dropout-16           [-1, 64, 16, 16]               0\n",
      "           Conv2d-17           [-1, 64, 16, 16]             576\n",
      "           Conv2d-18           [-1, 64, 16, 16]           4,096\n",
      "             ReLU-19           [-1, 64, 16, 16]               0\n",
      "      BatchNorm2d-20           [-1, 64, 16, 16]             128\n",
      "          Dropout-21           [-1, 64, 16, 16]               0\n",
      "           Conv2d-22             [-1, 32, 8, 8]          18,432\n",
      "           Conv2d-23             [-1, 32, 8, 8]             288\n",
      "           Conv2d-24             [-1, 64, 8, 8]           2,048\n",
      "             ReLU-25             [-1, 64, 8, 8]               0\n",
      "      BatchNorm2d-26             [-1, 64, 8, 8]             128\n",
      "          Dropout-27             [-1, 64, 8, 8]               0\n",
      "           Conv2d-28             [-1, 64, 8, 8]             576\n",
      "           Conv2d-29             [-1, 64, 8, 8]           4,096\n",
      "             ReLU-30             [-1, 64, 8, 8]               0\n",
      "      BatchNorm2d-31             [-1, 64, 8, 8]             128\n",
      "          Dropout-32             [-1, 64, 8, 8]               0\n",
      "           Conv2d-33             [-1, 64, 6, 6]             576\n",
      "           Conv2d-34             [-1, 64, 6, 6]           4,096\n",
      "             ReLU-35             [-1, 64, 6, 6]               0\n",
      "      BatchNorm2d-36             [-1, 64, 6, 6]             128\n",
      "          Dropout-37             [-1, 64, 6, 6]               0\n",
      "        AvgPool2d-38             [-1, 64, 1, 1]               0\n",
      "           Conv2d-39             [-1, 10, 1, 1]             640\n",
      "================================================================\n",
      "Total params: 59,483\n",
      "Trainable params: 59,483\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 4.92\n",
      "Params size (MB): 0.23\n",
      "Estimated Total Size (MB): 5.16\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary\n",
    "from torchsummary import summary\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "model = Net().to(device)\n",
    "summary(model, input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "  model.train()\n",
    "  pbar = tqdm(train_loader)\n",
    "  correct = 0\n",
    "  processed = 0\n",
    "  for batch_idx, (data, target) in enumerate(pbar):\n",
    "    # get samples\n",
    "    data, target = data.to(device), target.to(device)\n",
    "\n",
    "    # Init\n",
    "    optimizer.zero_grad()\n",
    "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n",
    "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
    "\n",
    "    # Predict\n",
    "    y_pred = model(data)\n",
    "\n",
    "    # Calculate loss\n",
    "    loss = F.nll_loss(y_pred, target)\n",
    "    train_losses.append(loss)\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Update pbar-tqdm\n",
    "    \n",
    "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    processed += len(data)\n",
    "\n",
    "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
    "    train_acc.append(100*correct/processed)\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    test_acc.append(100. * correct / len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/98 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.7379930019378662 Batch_id=97 Accuracy=27.20: 100%|██████████| 98/98 [00:14<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.6592, Accuracy: 3768/10000 (37.68%)\n",
      "\n",
      "EPOCH: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.4928193092346191 Batch_id=97 Accuracy=40.80: 100%|██████████| 98/98 [00:14<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.4399, Accuracy: 4695/10000 (46.95%)\n",
      "\n",
      "EPOCH: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.3503700494766235 Batch_id=97 Accuracy=46.74: 100%|██████████| 98/98 [00:14<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.3018, Accuracy: 5265/10000 (52.65%)\n",
      "\n",
      "EPOCH: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.26351797580719 Batch_id=97 Accuracy=50.97: 100%|██████████| 98/98 [00:14<00:00,  6.66it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.1882, Accuracy: 5669/10000 (56.69%)\n",
      "\n",
      "EPOCH: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.1558393239974976 Batch_id=97 Accuracy=53.94: 100%|██████████| 98/98 [00:14<00:00,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.1358, Accuracy: 5879/10000 (58.79%)\n",
      "\n",
      "EPOCH: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.1583260297775269 Batch_id=97 Accuracy=56.72: 100%|██████████| 98/98 [00:14<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.0829, Accuracy: 6066/10000 (60.66%)\n",
      "\n",
      "EPOCH: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.1729694604873657 Batch_id=97 Accuracy=58.23: 100%|██████████| 98/98 [00:11<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.0380, Accuracy: 6237/10000 (62.37%)\n",
      "\n",
      "EPOCH: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.0635501146316528 Batch_id=97 Accuracy=60.01: 100%|██████████| 98/98 [00:12<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.9868, Accuracy: 6459/10000 (64.59%)\n",
      "\n",
      "EPOCH: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.059478521347046 Batch_id=97 Accuracy=61.60: 100%|██████████| 98/98 [00:11<00:00,  8.24it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.9417, Accuracy: 6599/10000 (65.99%)\n",
      "\n",
      "EPOCH: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.0037305355072021 Batch_id=97 Accuracy=62.96: 100%|██████████| 98/98 [00:13<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8859, Accuracy: 6854/10000 (68.54%)\n",
      "\n",
      "EPOCH: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.029566764831543 Batch_id=97 Accuracy=64.05: 100%|██████████| 98/98 [00:12<00:00,  7.70it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8690, Accuracy: 6880/10000 (68.80%)\n",
      "\n",
      "EPOCH: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.0233745574951172 Batch_id=97 Accuracy=65.34: 100%|██████████| 98/98 [00:12<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8378, Accuracy: 6954/10000 (69.54%)\n",
      "\n",
      "EPOCH: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.018368124961853 Batch_id=97 Accuracy=65.94: 100%|██████████| 98/98 [00:12<00:00,  7.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8199, Accuracy: 7076/10000 (70.76%)\n",
      "\n",
      "EPOCH: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.9299193620681763 Batch_id=97 Accuracy=67.12: 100%|██████████| 98/98 [00:12<00:00,  8.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8306, Accuracy: 7029/10000 (70.29%)\n",
      "\n",
      "EPOCH: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.9022270441055298 Batch_id=97 Accuracy=67.61: 100%|██████████| 98/98 [00:12<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7669, Accuracy: 7264/10000 (72.64%)\n",
      "\n",
      "EPOCH: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.8651898503303528 Batch_id=97 Accuracy=68.56: 100%|██████████| 98/98 [00:12<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7650, Accuracy: 7326/10000 (73.26%)\n",
      "\n",
      "EPOCH: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.9428018927574158 Batch_id=97 Accuracy=69.02: 100%|██████████| 98/98 [00:12<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7609, Accuracy: 7293/10000 (72.93%)\n",
      "\n",
      "EPOCH: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.7722923755645752 Batch_id=97 Accuracy=69.33: 100%|██████████| 98/98 [00:11<00:00,  8.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7661, Accuracy: 7312/10000 (73.12%)\n",
      "\n",
      "EPOCH: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.8619638085365295 Batch_id=97 Accuracy=70.03: 100%|██████████| 98/98 [00:12<00:00,  7.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7310, Accuracy: 7442/10000 (74.42%)\n",
      "\n",
      "EPOCH: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.7821615934371948 Batch_id=97 Accuracy=70.59: 100%|██████████| 98/98 [00:13<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7115, Accuracy: 7493/10000 (74.93%)\n",
      "\n",
      "EPOCH: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.7992330193519592 Batch_id=97 Accuracy=70.82: 100%|██████████| 98/98 [00:12<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7066, Accuracy: 7546/10000 (75.46%)\n",
      "\n",
      "EPOCH: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.7988754510879517 Batch_id=97 Accuracy=71.10: 100%|██████████| 98/98 [00:12<00:00,  7.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6842, Accuracy: 7600/10000 (76.00%)\n",
      "\n",
      "EPOCH: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.7873977422714233 Batch_id=97 Accuracy=71.88: 100%|██████████| 98/98 [00:11<00:00,  8.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6776, Accuracy: 7649/10000 (76.49%)\n",
      "\n",
      "EPOCH: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.728409469127655 Batch_id=97 Accuracy=72.14: 100%|██████████| 98/98 [00:12<00:00,  7.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6836, Accuracy: 7622/10000 (76.22%)\n",
      "\n",
      "EPOCH: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.721322774887085 Batch_id=97 Accuracy=72.57: 100%|██████████| 98/98 [00:12<00:00,  7.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6605, Accuracy: 7732/10000 (77.32%)\n",
      "\n",
      "EPOCH: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.7466701865196228 Batch_id=97 Accuracy=72.94: 100%|██████████| 98/98 [00:13<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6680, Accuracy: 7704/10000 (77.04%)\n",
      "\n",
      "EPOCH: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.8027028441429138 Batch_id=97 Accuracy=72.61: 100%|██████████| 98/98 [00:12<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6447, Accuracy: 7811/10000 (78.11%)\n",
      "\n",
      "EPOCH: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.8653748631477356 Batch_id=97 Accuracy=73.37: 100%|██████████| 98/98 [00:14<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6337, Accuracy: 7814/10000 (78.14%)\n",
      "\n",
      "EPOCH: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.8442563414573669 Batch_id=97 Accuracy=73.63: 100%|██████████| 98/98 [00:14<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6695, Accuracy: 7703/10000 (77.03%)\n",
      "\n",
      "EPOCH: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.6615445017814636 Batch_id=97 Accuracy=73.65: 100%|██████████| 98/98 [00:15<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6355, Accuracy: 7813/10000 (78.13%)\n",
      "\n",
      "EPOCH: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.7193893790245056 Batch_id=97 Accuracy=73.99: 100%|██████████| 98/98 [00:14<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6721, Accuracy: 7708/10000 (77.08%)\n",
      "\n",
      "EPOCH: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.7133586406707764 Batch_id=16 Accuracy=74.46:  17%|█▋        | 17/98 [00:02<00:12,  6.50it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21316\\3813137402.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"EPOCH:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;31m# scheduler.step()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21316\\2788663481.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[0;32m     11\u001b[0m   \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m   \u001b[0mprocessed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m   \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpbar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;31m# get samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mi:\\Installs\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1195\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1196\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mi:\\Installs\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    679\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mi:\\Installs\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 721\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    722\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mi:\\Installs\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mi:\\Installs\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21316\\518497575.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mtransformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"image\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mi:\\Installs\\lib\\site-packages\\albumentations\\core\\composition.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcheck_each_transform\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mi:\\Installs\\lib\\site-packages\\albumentations\\core\\transforms_interface.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, force_apply, *args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m                     )\n\u001b[0;32m    117\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_with_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mi:\\Installs\\lib\\site-packages\\albumentations\\core\\transforms_interface.py\u001b[0m in \u001b[0;36mapply_with_params\u001b[1;34m(self, params, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m                 \u001b[0mtarget_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_target_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                 \u001b[0mtarget_dependencies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_dependence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m                 \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtarget_dependencies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m                 \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mi:\\Installs\\lib\\site-packages\\albumentations\\augmentations\\geometric\\transforms.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, img, pad_top, pad_bottom, pad_left, pad_right, **params)\u001b[0m\n\u001b[0;32m   1078\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad_top\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad_bottom\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad_left\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad_right\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1079\u001b[0m     ) -> np.ndarray:\n\u001b[1;32m-> 1080\u001b[1;33m         return F.pad_with_params(\n\u001b[0m\u001b[0;32m   1081\u001b[0m             \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m             \u001b[0mpad_top\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mi:\\Installs\\lib\\site-packages\\albumentations\\augmentations\\utils.py\u001b[0m in \u001b[0;36mwrapped_function\u001b[1;34m(img, *args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mi:\\Installs\\lib\\site-packages\\albumentations\\augmentations\\geometric\\functional.py\u001b[0m in \u001b[0;36mpad_with_params\u001b[1;34m(img, h_pad_top, h_pad_bottom, w_pad_left, w_pad_right, border_mode, value)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m     )\n\u001b[1;32m-> 1110\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mi:\\Installs\\lib\\site-packages\\albumentations\\augmentations\\utils.py\u001b[0m in \u001b[0;36m__process_fn\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "model =  Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "# scheduler = StepLR(optimizer, step_size=6, gamma=0.1)\n",
    "\n",
    "\n",
    "EPOCHS = 50\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"EPOCH:\", epoch)\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    # scheduler.step()\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8fbfcbe0e544000e4ba3d2d9974592a7ba1a2af52205db5302ae41a0c45d995"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
