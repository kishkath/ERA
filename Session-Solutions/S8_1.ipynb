{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train Phase transformations\n",
    "# train_transforms = transforms.Compose([\n",
    "#                                       #  transforms.Resize((28, 28)),\n",
    "#                                       #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
    "#                                        transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
    "#                                        transforms.RandomHorizontalFlip(),\n",
    "#                                        transforms.RandomRotation(15),\n",
    "#                                        transforms.ToTensor(),\n",
    "#                                        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values. \n",
    "#                                        # Note the difference between (0.1307) and (0.1307,)\n",
    "#                                        ])\n",
    "\n",
    "# # Test Phase transformations\n",
    "# test_transforms = transforms.Compose([\n",
    "#                                       #  transforms.Resize((28, 28)),\n",
    "#                                       #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
    "#                                        transforms.ToTensor(),\n",
    "#                                        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "#                                        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = [0.4914, 0.4822, 0.4465]\n",
    "stds = [0.2470, 0.2435, 0.2616]\n",
    "\n",
    "train_transforms = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=means, std=stds, always_apply=True),\n",
    "        A.PadIfNeeded(min_height=40, min_width=40, always_apply=True),\n",
    "        A.RandomCrop(height=32, width=32, always_apply=True),\n",
    "        A.HorizontalFlip(),\n",
    "        A.CoarseDropout(max_holes=1, max_height=8, max_width=8, min_holes=1, min_height=8, min_width=8, fill_value=means),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transforms = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=means, std=stds, always_apply=True),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar10SearchDataset(datasets.CIFAR10):\n",
    "\n",
    "    def __init__(self, root=\"~/data\", train=True, download=True, transform=None):\n",
    "\n",
    "        super().__init__(root=root, train=train, download=download, transform=transform)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image, label = self.data[index], self.targets[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "\n",
    "            transformed = self.transform(image=image)\n",
    "\n",
    "            image = transformed[\"image\"]\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train = Cifar10SearchDataset(root='./data', train=True,\n",
    "                                        download=True, transform=train_transforms)\n",
    "test = Cifar10SearchDataset(root='./data', train=False,\n",
    "                                       download=True, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available? True\n"
     ]
    }
   ],
   "source": [
    "SEED = 1\n",
    "\n",
    "# CUDA?\n",
    "cuda = torch.cuda.is_available()\n",
    "print(\"CUDA Available?\", cuda)\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# dataloader arguments - something you'll fetch these from cmdprmt\n",
    "dataloader_args = dict(shuffle=True, batch_size=512, num_workers=0, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
    "\n",
    "# train dataloader\n",
    "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
    "\n",
    "# test dataloader\n",
    "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ship  bird  cat   dog  \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "import torchvision\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[:4]))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "dropout_value = 0.1\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # CONVOLUTION BLOCK 1 input 32/1/1\n",
    "        self.convblock1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
    "\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 32/3/1\n",
    "\n",
    "        \n",
    "        self.convblock2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, groups=32, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.Conv2d(in_channels=32, out_channels=128, kernel_size=(1, 1), padding=0, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 32/5/1\n",
    "\n",
    "        # TRANSITION BLOCK 1\n",
    "        self.convblock3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=128, \n",
    "                out_channels=64, \n",
    "                kernel_size=(3,3), \n",
    "                padding=2, \n",
    "                stride=2, \n",
    "                dilation=2, \n",
    "                bias=False),\n",
    "        ) # output_size = 16/7/2\n",
    "\n",
    "        # CONVOLUTION BLOCK 2\n",
    "        self.convblock4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, groups=64, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(1, 1), padding=0, bias=False),\n",
    "            nn.ReLU(),            \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 16/11/2\n",
    "\n",
    "        self.convblock5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, groups=128, out_channels=128, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(1, 1), padding=0, bias=False),\n",
    "            nn.ReLU(),            \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 16/15/2\n",
    "\n",
    "        # TRANSITION BLOCK 2\n",
    "        self.convblock6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, \n",
    "                      out_channels=64, \n",
    "                      kernel_size=(3,3), \n",
    "                      padding=2, \n",
    "                      dilation=2,\n",
    "                      stride=2, \n",
    "                      bias=False),\n",
    "        ) # output_size = 8/19/4\n",
    "\n",
    "        self.convblock7 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, groups=64, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(1, 1), padding=0, bias=False),\n",
    "            nn.ReLU(),            \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 8/24/4\n",
    "        self.convblock8 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, groups = 64, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(1, 1), padding=0, bias=False),\n",
    "            nn.ReLU(),            \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 8/32/4\n",
    "\n",
    "        self.convblock9 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, groups=64,  out_channels=64, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(1, 1), padding=0, bias=False),\n",
    "            nn.ReLU(),            \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 6/40/4\n",
    "        \n",
    "        # OUTPUT BLOCK\n",
    "        self.gap = nn.Sequential(\n",
    "            nn.AvgPool2d(kernel_size=6)\n",
    "        ) # output_size = 1/64\n",
    "\n",
    "        self.convblock10 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n",
    "            # nn.BatchNorm2d(10),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(dropout_value)\n",
    "        ) \n",
    "\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_value)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convblock1(x)\n",
    "        x = self.convblock2(x)\n",
    "        x = self.convblock3(x)\n",
    "        x = self.convblock4(x)\n",
    "        x = self.convblock5(x)\n",
    "        x = self.convblock6(x)\n",
    "        x = self.convblock7(x)\n",
    "        x = self.convblock8(x)\n",
    "        x = self.convblock9(x)\n",
    "        x = self.gap(x)        \n",
    "        x = self.convblock10(x)\n",
    "\n",
    "        x = x.view(-1, 10)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in i:\\installs\\lib\\site-packages (1.5.1)\n",
      "cuda\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 32, 32]             864\n",
      "              ReLU-2           [-1, 32, 32, 32]               0\n",
      "       BatchNorm2d-3           [-1, 32, 32, 32]              64\n",
      "           Dropout-4           [-1, 32, 32, 32]               0\n",
      "            Conv2d-5           [-1, 32, 32, 32]             288\n",
      "            Conv2d-6          [-1, 128, 32, 32]           4,096\n",
      "              ReLU-7          [-1, 128, 32, 32]               0\n",
      "       BatchNorm2d-8          [-1, 128, 32, 32]             256\n",
      "           Dropout-9          [-1, 128, 32, 32]               0\n",
      "           Conv2d-10           [-1, 64, 16, 16]          73,728\n",
      "           Conv2d-11           [-1, 64, 16, 16]             576\n",
      "           Conv2d-12          [-1, 128, 16, 16]           8,192\n",
      "             ReLU-13          [-1, 128, 16, 16]               0\n",
      "      BatchNorm2d-14          [-1, 128, 16, 16]             256\n",
      "          Dropout-15          [-1, 128, 16, 16]               0\n",
      "           Conv2d-16          [-1, 128, 16, 16]           1,152\n",
      "           Conv2d-17          [-1, 128, 16, 16]          16,384\n",
      "             ReLU-18          [-1, 128, 16, 16]               0\n",
      "      BatchNorm2d-19          [-1, 128, 16, 16]             256\n",
      "          Dropout-20          [-1, 128, 16, 16]               0\n",
      "           Conv2d-21             [-1, 64, 8, 8]          73,728\n",
      "           Conv2d-22             [-1, 64, 8, 8]             576\n",
      "           Conv2d-23             [-1, 64, 8, 8]           4,096\n",
      "             ReLU-24             [-1, 64, 8, 8]               0\n",
      "      BatchNorm2d-25             [-1, 64, 8, 8]             128\n",
      "          Dropout-26             [-1, 64, 8, 8]               0\n",
      "           Conv2d-27             [-1, 64, 8, 8]             576\n",
      "           Conv2d-28             [-1, 64, 8, 8]           4,096\n",
      "             ReLU-29             [-1, 64, 8, 8]               0\n",
      "      BatchNorm2d-30             [-1, 64, 8, 8]             128\n",
      "          Dropout-31             [-1, 64, 8, 8]               0\n",
      "           Conv2d-32             [-1, 64, 6, 6]             576\n",
      "           Conv2d-33             [-1, 64, 6, 6]           4,096\n",
      "             ReLU-34             [-1, 64, 6, 6]               0\n",
      "      BatchNorm2d-35             [-1, 64, 6, 6]             128\n",
      "          Dropout-36             [-1, 64, 6, 6]               0\n",
      "        AvgPool2d-37             [-1, 64, 1, 1]               0\n",
      "           Conv2d-38             [-1, 10, 1, 1]             640\n",
      "================================================================\n",
      "Total params: 194,880\n",
      "Trainable params: 194,880\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 8.18\n",
      "Params size (MB): 0.74\n",
      "Estimated Total Size (MB): 8.94\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the 'I:\\Installs\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary\n",
    "from torchsummary import summary\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "model = Net().to(device)\n",
    "summary(model, input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "  model.train()\n",
    "  pbar = tqdm(train_loader)\n",
    "  correct = 0\n",
    "  processed = 0\n",
    "  for batch_idx, (data, target) in enumerate(pbar):\n",
    "    # get samples\n",
    "    data, target = data.to(device), target.to(device)\n",
    "\n",
    "    # Init\n",
    "    optimizer.zero_grad()\n",
    "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n",
    "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
    "\n",
    "    # Predict\n",
    "    y_pred = model(data)\n",
    "\n",
    "    # Calculate loss\n",
    "    loss = F.nll_loss(y_pred, target)\n",
    "    train_losses.append(loss)\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Update pbar-tqdm\n",
    "    \n",
    "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    processed += len(data)\n",
    "\n",
    "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
    "    train_acc.append(100*correct/processed)\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    test_acc.append(100. * correct / len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/98 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.5938913822174072 Batch_id=97 Accuracy=31.25: 100%|██████████| 98/98 [00:16<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.6163, Accuracy: 3995/10000 (39.95%)\n",
      "\n",
      "EPOCH: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.4642003774642944 Batch_id=97 Accuracy=46.25: 100%|██████████| 98/98 [00:15<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.3231, Accuracy: 5156/10000 (51.56%)\n",
      "\n",
      "EPOCH: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.2435015439987183 Batch_id=97 Accuracy=53.36: 100%|██████████| 98/98 [00:16<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.1749, Accuracy: 5809/10000 (58.09%)\n",
      "\n",
      "EPOCH: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.0438508987426758 Batch_id=97 Accuracy=58.43: 100%|██████████| 98/98 [00:13<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.0449, Accuracy: 6238/10000 (62.38%)\n",
      "\n",
      "EPOCH: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.1010385751724243 Batch_id=97 Accuracy=61.22: 100%|██████████| 98/98 [00:11<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.9762, Accuracy: 6498/10000 (64.98%)\n",
      "\n",
      "EPOCH: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.0104234218597412 Batch_id=97 Accuracy=63.15: 100%|██████████| 98/98 [00:11<00:00,  8.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.9214, Accuracy: 6671/10000 (66.71%)\n",
      "\n",
      "EPOCH: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.0122969150543213 Batch_id=97 Accuracy=65.47: 100%|██████████| 98/98 [00:11<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.9024, Accuracy: 6788/10000 (67.88%)\n",
      "\n",
      "EPOCH: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.9157723188400269 Batch_id=97 Accuracy=66.86: 100%|██████████| 98/98 [00:11<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8340, Accuracy: 7054/10000 (70.54%)\n",
      "\n",
      "EPOCH: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.8863223791122437 Batch_id=97 Accuracy=68.14: 100%|██████████| 98/98 [00:12<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7798, Accuracy: 7300/10000 (73.00%)\n",
      "\n",
      "EPOCH: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.8446061015129089 Batch_id=97 Accuracy=69.73: 100%|██████████| 98/98 [00:12<00:00,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7529, Accuracy: 7397/10000 (73.97%)\n",
      "\n",
      "EPOCH: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.8193402290344238 Batch_id=97 Accuracy=70.87: 100%|██████████| 98/98 [00:11<00:00,  8.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7364, Accuracy: 7407/10000 (74.07%)\n",
      "\n",
      "EPOCH: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.7291877865791321 Batch_id=97 Accuracy=71.68: 100%|██████████| 98/98 [00:11<00:00,  8.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7025, Accuracy: 7578/10000 (75.78%)\n",
      "\n",
      "EPOCH: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.7293088436126709 Batch_id=97 Accuracy=72.68: 100%|██████████| 98/98 [00:11<00:00,  8.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7081, Accuracy: 7532/10000 (75.32%)\n",
      "\n",
      "EPOCH: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.6605973243713379 Batch_id=97 Accuracy=73.48: 100%|██████████| 98/98 [00:11<00:00,  8.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6684, Accuracy: 7679/10000 (76.79%)\n",
      "\n",
      "EPOCH: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.7200950384140015 Batch_id=97 Accuracy=74.04: 100%|██████████| 98/98 [00:12<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6332, Accuracy: 7750/10000 (77.50%)\n",
      "\n",
      "EPOCH: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.7732340693473816 Batch_id=97 Accuracy=74.71: 100%|██████████| 98/98 [00:11<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6379, Accuracy: 7784/10000 (77.84%)\n",
      "\n",
      "EPOCH: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.7403805255889893 Batch_id=97 Accuracy=75.30: 100%|██████████| 98/98 [00:11<00:00,  8.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6386, Accuracy: 7807/10000 (78.07%)\n",
      "\n",
      "EPOCH: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.6598532199859619 Batch_id=97 Accuracy=75.56: 100%|██████████| 98/98 [00:11<00:00,  8.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6314, Accuracy: 7835/10000 (78.35%)\n",
      "\n",
      "EPOCH: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.685737133026123 Batch_id=97 Accuracy=76.26: 100%|██████████| 98/98 [00:11<00:00,  8.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6172, Accuracy: 7882/10000 (78.82%)\n",
      "\n",
      "EPOCH: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5705410242080688 Batch_id=97 Accuracy=77.18: 100%|██████████| 98/98 [00:11<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6087, Accuracy: 7896/10000 (78.96%)\n",
      "\n",
      "EPOCH: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.7721759080886841 Batch_id=97 Accuracy=77.04: 100%|██████████| 98/98 [00:13<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5756, Accuracy: 8029/10000 (80.29%)\n",
      "\n",
      "EPOCH: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5492364764213562 Batch_id=97 Accuracy=77.73: 100%|██████████| 98/98 [00:11<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5594, Accuracy: 8088/10000 (80.88%)\n",
      "\n",
      "EPOCH: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.6762881278991699 Batch_id=97 Accuracy=77.82: 100%|██████████| 98/98 [00:11<00:00,  8.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5574, Accuracy: 8058/10000 (80.58%)\n",
      "\n",
      "EPOCH: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5607526898384094 Batch_id=97 Accuracy=78.29: 100%|██████████| 98/98 [00:11<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5938, Accuracy: 7983/10000 (79.83%)\n",
      "\n",
      "EPOCH: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.6173791885375977 Batch_id=97 Accuracy=78.73: 100%|██████████| 98/98 [00:11<00:00,  8.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5462, Accuracy: 8153/10000 (81.53%)\n",
      "\n",
      "EPOCH: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.6635943055152893 Batch_id=97 Accuracy=79.07: 100%|██████████| 98/98 [00:11<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5246, Accuracy: 8198/10000 (81.98%)\n",
      "\n",
      "EPOCH: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.6032050251960754 Batch_id=97 Accuracy=79.29: 100%|██████████| 98/98 [00:11<00:00,  8.39it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5171, Accuracy: 8249/10000 (82.49%)\n",
      "\n",
      "EPOCH: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.566018283367157 Batch_id=97 Accuracy=79.40: 100%|██████████| 98/98 [00:11<00:00,  8.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5288, Accuracy: 8155/10000 (81.55%)\n",
      "\n",
      "EPOCH: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5335061550140381 Batch_id=97 Accuracy=79.59: 100%|██████████| 98/98 [00:11<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5261, Accuracy: 8210/10000 (82.10%)\n",
      "\n",
      "EPOCH: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5727697014808655 Batch_id=97 Accuracy=80.13: 100%|██████████| 98/98 [00:13<00:00,  7.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5263, Accuracy: 8212/10000 (82.12%)\n",
      "\n",
      "EPOCH: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.530617892742157 Batch_id=97 Accuracy=80.29: 100%|██████████| 98/98 [00:15<00:00,  6.38it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5272, Accuracy: 8225/10000 (82.25%)\n",
      "\n",
      "EPOCH: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5487827658653259 Batch_id=97 Accuracy=80.51: 100%|██████████| 98/98 [00:14<00:00,  6.61it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5158, Accuracy: 8284/10000 (82.84%)\n",
      "\n",
      "EPOCH: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5386143922805786 Batch_id=97 Accuracy=80.95: 100%|██████████| 98/98 [00:11<00:00,  8.21it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4998, Accuracy: 8319/10000 (83.19%)\n",
      "\n",
      "EPOCH: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.6247193813323975 Batch_id=97 Accuracy=81.19: 100%|██████████| 98/98 [00:11<00:00,  8.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5073, Accuracy: 8293/10000 (82.93%)\n",
      "\n",
      "EPOCH: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.491117388010025 Batch_id=97 Accuracy=81.30: 100%|██████████| 98/98 [00:11<00:00,  8.54it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4968, Accuracy: 8333/10000 (83.33%)\n",
      "\n",
      "EPOCH: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.555752158164978 Batch_id=97 Accuracy=81.58: 100%|██████████| 98/98 [00:11<00:00,  8.37it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4914, Accuracy: 8343/10000 (83.43%)\n",
      "\n",
      "EPOCH: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5638745427131653 Batch_id=97 Accuracy=81.58: 100%|██████████| 98/98 [00:12<00:00,  8.06it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4712, Accuracy: 8441/10000 (84.41%)\n",
      "\n",
      "EPOCH: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5040097236633301 Batch_id=97 Accuracy=82.06: 100%|██████████| 98/98 [00:11<00:00,  8.26it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4565, Accuracy: 8472/10000 (84.72%)\n",
      "\n",
      "EPOCH: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.49843543767929077 Batch_id=97 Accuracy=82.18: 100%|██████████| 98/98 [00:11<00:00,  8.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4653, Accuracy: 8415/10000 (84.15%)\n",
      "\n",
      "EPOCH: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5320570468902588 Batch_id=97 Accuracy=82.31: 100%|██████████| 98/98 [00:11<00:00,  8.35it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4574, Accuracy: 8485/10000 (84.85%)\n",
      "\n",
      "EPOCH: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.552270770072937 Batch_id=97 Accuracy=82.47: 100%|██████████| 98/98 [00:11<00:00,  8.49it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4798, Accuracy: 8373/10000 (83.73%)\n",
      "\n",
      "EPOCH: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5134892463684082 Batch_id=97 Accuracy=82.53: 100%|██████████| 98/98 [00:11<00:00,  8.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4842, Accuracy: 8393/10000 (83.93%)\n",
      "\n",
      "EPOCH: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.4878634512424469 Batch_id=97 Accuracy=82.66: 100%|██████████| 98/98 [00:11<00:00,  8.38it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4439, Accuracy: 8523/10000 (85.23%)\n",
      "\n",
      "EPOCH: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5141604542732239 Batch_id=97 Accuracy=82.73: 100%|██████████| 98/98 [00:11<00:00,  8.49it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4406, Accuracy: 8523/10000 (85.23%)\n",
      "\n",
      "EPOCH: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5114307999610901 Batch_id=97 Accuracy=83.04: 100%|██████████| 98/98 [00:11<00:00,  8.35it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4738, Accuracy: 8423/10000 (84.23%)\n",
      "\n",
      "EPOCH: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5643962025642395 Batch_id=97 Accuracy=83.34: 100%|██████████| 98/98 [00:12<00:00,  8.14it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4349, Accuracy: 8554/10000 (85.54%)\n",
      "\n",
      "EPOCH: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.49583226442337036 Batch_id=97 Accuracy=83.35: 100%|██████████| 98/98 [00:11<00:00,  8.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4701, Accuracy: 8444/10000 (84.44%)\n",
      "\n",
      "EPOCH: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.47713610529899597 Batch_id=97 Accuracy=83.64: 100%|██████████| 98/98 [00:11<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4529, Accuracy: 8511/10000 (85.11%)\n",
      "\n",
      "EPOCH: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5024678111076355 Batch_id=97 Accuracy=83.66: 100%|██████████| 98/98 [00:11<00:00,  8.51it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4500, Accuracy: 8503/10000 (85.03%)\n",
      "\n",
      "EPOCH: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.39015769958496094 Batch_id=97 Accuracy=83.56: 100%|██████████| 98/98 [00:11<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4364, Accuracy: 8570/10000 (85.70%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "model =  Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "# scheduler = StepLR(optimizer, step_size=6, gamma=0.1)\n",
    "\n",
    "\n",
    "EPOCHS = 50\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"EPOCH:\", epoch)\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    # scheduler.step()\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8fbfcbe0e544000e4ba3d2d9974592a7ba1a2af52205db5302ae41a0c45d995"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
