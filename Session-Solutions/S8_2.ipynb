{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Phase transformations\n",
    "train_transforms = transforms.Compose([\n",
    "                                      #  transforms.Resize((28, 28)),\n",
    "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
    "                                       transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.RandomRotation(15),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values. \n",
    "                                       # Note the difference between (0.1307) and (0.1307,)\n",
    "                                       ])\n",
    "\n",
    "# Test Phase transformations\n",
    "test_transforms = transforms.Compose([\n",
    "                                      #  transforms.Resize((28, 28)),\n",
    "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                                       ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train = datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=train_transforms)\n",
    "test = datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available? True\n"
     ]
    }
   ],
   "source": [
    "SEED = 1\n",
    "\n",
    "# CUDA?\n",
    "cuda = torch.cuda.is_available()\n",
    "print(\"CUDA Available?\", cuda)\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# dataloader arguments - something you'll fetch these from cmdprmt\n",
    "dataloader_args = dict(shuffle=True, batch_size=512, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
    "\n",
    "# train dataloader\n",
    "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
    "\n",
    "# test dataloader\n",
    "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ship  bird  cat   dog  \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "import torchvision\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[:4]))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "dropout_value = 0.1\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # CONVOLUTION BLOCK 1 input 32/1/1\n",
    "        self.convblock1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 32/3/1\n",
    "\n",
    "        \n",
    "        self.convblock2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 32/5/1\n",
    "\n",
    "        # TRANSITION BLOCK 1\n",
    "        self.convblock3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=(3,3), padding=1, stride=2, bias=False),\n",
    "        ) # output_size = 16/7/2\n",
    "\n",
    "        # CONVOLUTION BLOCK 2\n",
    "        self.convblock4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),            \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 16/11/2\n",
    "\n",
    "        self.convblock5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),            \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 16/15/2\n",
    "\n",
    "        # TRANSITION BLOCK 2\n",
    "        self.convblock6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=(3,3) , padding=1, stride=2, bias=False),\n",
    "        ) # output_size = 16/19/4\n",
    "\n",
    "        self.convblock7 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),            \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 8/24/4\n",
    "        self.convblock8 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),            \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 8/32/4\n",
    "\n",
    "        self.convblock9 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.ReLU(),            \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 6/40/4\n",
    "        \n",
    "        # OUTPUT BLOCK\n",
    "        self.gap = nn.Sequential(\n",
    "            nn.AvgPool2d(kernel_size=6)\n",
    "        ) # output_size = 1/64\n",
    "\n",
    "        self.convblock10 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n",
    "            # nn.BatchNorm2d(10),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(dropout_value)\n",
    "        ) \n",
    "\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_value)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convblock1(x)\n",
    "        x = self.convblock2(x)\n",
    "        x = self.convblock3(x)\n",
    "        x = self.convblock4(x)\n",
    "        x = self.convblock5(x)\n",
    "        x = self.convblock6(x)\n",
    "        x = self.convblock7(x)\n",
    "        x = self.convblock8(x)\n",
    "        x = self.convblock9(x)\n",
    "        x = self.gap(x)        \n",
    "        x = self.convblock10(x)\n",
    "\n",
    "        x = x.view(-1, 10)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in i:\\installs\\lib\\site-packages (1.5.1)\n",
      "cuda\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 32, 32]             864\n",
      "              ReLU-2           [-1, 32, 32, 32]               0\n",
      "       BatchNorm2d-3           [-1, 32, 32, 32]              64\n",
      "           Dropout-4           [-1, 32, 32, 32]               0\n",
      "            Conv2d-5           [-1, 64, 32, 32]          18,432\n",
      "              ReLU-6           [-1, 64, 32, 32]               0\n",
      "       BatchNorm2d-7           [-1, 64, 32, 32]             128\n",
      "           Dropout-8           [-1, 64, 32, 32]               0\n",
      "            Conv2d-9           [-1, 32, 16, 16]          18,432\n",
      "           Conv2d-10           [-1, 64, 16, 16]          18,432\n",
      "             ReLU-11           [-1, 64, 16, 16]               0\n",
      "      BatchNorm2d-12           [-1, 64, 16, 16]             128\n",
      "          Dropout-13           [-1, 64, 16, 16]               0\n",
      "           Conv2d-14           [-1, 64, 16, 16]          36,864\n",
      "             ReLU-15           [-1, 64, 16, 16]               0\n",
      "      BatchNorm2d-16           [-1, 64, 16, 16]             128\n",
      "          Dropout-17           [-1, 64, 16, 16]               0\n",
      "           Conv2d-18             [-1, 32, 8, 8]          18,432\n",
      "           Conv2d-19             [-1, 64, 8, 8]          18,432\n",
      "             ReLU-20             [-1, 64, 8, 8]               0\n",
      "      BatchNorm2d-21             [-1, 64, 8, 8]             128\n",
      "          Dropout-22             [-1, 64, 8, 8]               0\n",
      "           Conv2d-23             [-1, 64, 8, 8]          36,864\n",
      "             ReLU-24             [-1, 64, 8, 8]               0\n",
      "      BatchNorm2d-25             [-1, 64, 8, 8]             128\n",
      "          Dropout-26             [-1, 64, 8, 8]               0\n",
      "           Conv2d-27             [-1, 64, 6, 6]          36,864\n",
      "             ReLU-28             [-1, 64, 6, 6]               0\n",
      "      BatchNorm2d-29             [-1, 64, 6, 6]             128\n",
      "          Dropout-30             [-1, 64, 6, 6]               0\n",
      "        AvgPool2d-31             [-1, 64, 1, 1]               0\n",
      "           Conv2d-32             [-1, 10, 1, 1]             640\n",
      "================================================================\n",
      "Total params: 205,088\n",
      "Trainable params: 205,088\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 4.40\n",
      "Params size (MB): 0.78\n",
      "Estimated Total Size (MB): 5.19\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the 'I:\\Installs\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary\n",
    "from torchsummary import summary\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "model = Net().to(device)\n",
    "summary(model, input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "  model.train()\n",
    "  pbar = tqdm(train_loader)\n",
    "  correct = 0\n",
    "  processed = 0\n",
    "  for batch_idx, (data, target) in enumerate(pbar):\n",
    "    # get samples\n",
    "    data, target = data.to(device), target.to(device)\n",
    "\n",
    "    # Init\n",
    "    optimizer.zero_grad()\n",
    "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n",
    "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
    "\n",
    "    # Predict\n",
    "    y_pred = model(data)\n",
    "\n",
    "    # Calculate loss\n",
    "    loss = F.nll_loss(y_pred, target)\n",
    "    train_losses.append(loss)\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Update pbar-tqdm\n",
    "    \n",
    "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    processed += len(data)\n",
    "\n",
    "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
    "    train_acc.append(100*correct/processed)\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    test_acc.append(100. * correct / len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.5572335720062256 Batch_id=97 Accuracy=34.13: 100%|██████████| 98/98 [00:17<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.4808, Accuracy: 4542/10000 (45.42%)\n",
      "\n",
      "EPOCH: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.3939290046691895 Batch_id=97 Accuracy=48.94: 100%|██████████| 98/98 [00:16<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.2309, Accuracy: 5470/10000 (54.70%)\n",
      "\n",
      "EPOCH: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.1082093715667725 Batch_id=97 Accuracy=56.39: 100%|██████████| 98/98 [00:17<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.1028, Accuracy: 6043/10000 (60.43%)\n",
      "\n",
      "EPOCH: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.0099539756774902 Batch_id=97 Accuracy=60.35: 100%|██████████| 98/98 [00:17<00:00,  5.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.9782, Accuracy: 6573/10000 (65.73%)\n",
      "\n",
      "EPOCH: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.0198757648468018 Batch_id=97 Accuracy=63.42: 100%|██████████| 98/98 [00:17<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.9605, Accuracy: 6603/10000 (66.03%)\n",
      "\n",
      "EPOCH: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.9235271215438843 Batch_id=97 Accuracy=66.13: 100%|██████████| 98/98 [00:17<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8360, Accuracy: 7077/10000 (70.77%)\n",
      "\n",
      "EPOCH: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.8259003758430481 Batch_id=97 Accuracy=67.71: 100%|██████████| 98/98 [00:17<00:00,  5.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8384, Accuracy: 7051/10000 (70.51%)\n",
      "\n",
      "EPOCH: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.8911172151565552 Batch_id=97 Accuracy=69.00: 100%|██████████| 98/98 [00:17<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7473, Accuracy: 7314/10000 (73.14%)\n",
      "\n",
      "EPOCH: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.8696908354759216 Batch_id=97 Accuracy=70.59: 100%|██████████| 98/98 [00:17<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7357, Accuracy: 7470/10000 (74.70%)\n",
      "\n",
      "EPOCH: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.7489931583404541 Batch_id=97 Accuracy=71.82: 100%|██████████| 98/98 [00:17<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6928, Accuracy: 7574/10000 (75.74%)\n",
      "\n",
      "EPOCH: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.6624415516853333 Batch_id=97 Accuracy=72.84: 100%|██████████| 98/98 [00:17<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6458, Accuracy: 7790/10000 (77.90%)\n",
      "\n",
      "EPOCH: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.7461172342300415 Batch_id=97 Accuracy=73.49: 100%|██████████| 98/98 [00:17<00:00,  5.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6422, Accuracy: 7763/10000 (77.63%)\n",
      "\n",
      "EPOCH: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.7854366302490234 Batch_id=97 Accuracy=74.71: 100%|██████████| 98/98 [00:17<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6120, Accuracy: 7869/10000 (78.69%)\n",
      "\n",
      "EPOCH: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.776220440864563 Batch_id=97 Accuracy=75.23: 100%|██████████| 98/98 [00:17<00:00,  5.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5852, Accuracy: 7974/10000 (79.74%)\n",
      "\n",
      "EPOCH: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.6676800847053528 Batch_id=97 Accuracy=76.22: 100%|██████████| 98/98 [00:17<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5833, Accuracy: 7974/10000 (79.74%)\n",
      "\n",
      "EPOCH: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.6034207344055176 Batch_id=97 Accuracy=76.80: 100%|██████████| 98/98 [00:17<00:00,  5.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5916, Accuracy: 7990/10000 (79.90%)\n",
      "\n",
      "EPOCH: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.6329149007797241 Batch_id=97 Accuracy=77.57: 100%|██████████| 98/98 [00:17<00:00,  5.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5418, Accuracy: 8143/10000 (81.43%)\n",
      "\n",
      "EPOCH: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.658799409866333 Batch_id=97 Accuracy=77.64: 100%|██████████| 98/98 [00:17<00:00,  5.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5387, Accuracy: 8168/10000 (81.68%)\n",
      "\n",
      "EPOCH: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.6878268718719482 Batch_id=97 Accuracy=78.20: 100%|██████████| 98/98 [00:17<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5180, Accuracy: 8205/10000 (82.05%)\n",
      "\n",
      "EPOCH: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.6670734286308289 Batch_id=97 Accuracy=78.74: 100%|██████████| 98/98 [00:17<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.5041, Accuracy: 8267/10000 (82.67%)\n",
      "\n",
      "EPOCH: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.6240975856781006 Batch_id=97 Accuracy=79.26: 100%|██████████| 98/98 [00:17<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4788, Accuracy: 8355/10000 (83.55%)\n",
      "\n",
      "EPOCH: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5812996029853821 Batch_id=97 Accuracy=79.52: 100%|██████████| 98/98 [00:17<00:00,  5.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4992, Accuracy: 8289/10000 (82.89%)\n",
      "\n",
      "EPOCH: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5776241421699524 Batch_id=97 Accuracy=80.20: 100%|██████████| 98/98 [00:17<00:00,  5.62it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4858, Accuracy: 8338/10000 (83.38%)\n",
      "\n",
      "EPOCH: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5806297063827515 Batch_id=97 Accuracy=80.30: 100%|██████████| 98/98 [00:17<00:00,  5.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4849, Accuracy: 8342/10000 (83.42%)\n",
      "\n",
      "EPOCH: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5845853090286255 Batch_id=97 Accuracy=80.48: 100%|██████████| 98/98 [00:17<00:00,  5.67it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4776, Accuracy: 8359/10000 (83.59%)\n",
      "\n",
      "EPOCH: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5143145322799683 Batch_id=97 Accuracy=81.05: 100%|██████████| 98/98 [00:17<00:00,  5.58it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4659, Accuracy: 8384/10000 (83.84%)\n",
      "\n",
      "EPOCH: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.4287291467189789 Batch_id=97 Accuracy=81.30: 100%|██████████| 98/98 [00:17<00:00,  5.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4540, Accuracy: 8419/10000 (84.19%)\n",
      "\n",
      "EPOCH: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.4865144193172455 Batch_id=97 Accuracy=81.58: 100%|██████████| 98/98 [00:17<00:00,  5.52it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4455, Accuracy: 8437/10000 (84.37%)\n",
      "\n",
      "EPOCH: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.4983864426612854 Batch_id=97 Accuracy=81.65: 100%|██████████| 98/98 [00:17<00:00,  5.62it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4611, Accuracy: 8389/10000 (83.89%)\n",
      "\n",
      "EPOCH: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.468705952167511 Batch_id=97 Accuracy=81.94: 100%|██████████| 98/98 [00:17<00:00,  5.57it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4412, Accuracy: 8480/10000 (84.80%)\n",
      "\n",
      "EPOCH: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.49172741174697876 Batch_id=97 Accuracy=82.23: 100%|██████████| 98/98 [00:17<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4408, Accuracy: 8497/10000 (84.97%)\n",
      "\n",
      "EPOCH: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5086914300918579 Batch_id=97 Accuracy=82.61: 100%|██████████| 98/98 [00:17<00:00,  5.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4291, Accuracy: 8545/10000 (85.45%)\n",
      "\n",
      "EPOCH: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5129307508468628 Batch_id=97 Accuracy=82.71: 100%|██████████| 98/98 [00:17<00:00,  5.51it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4208, Accuracy: 8548/10000 (85.48%)\n",
      "\n",
      "EPOCH: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5314809083938599 Batch_id=97 Accuracy=82.87: 100%|██████████| 98/98 [00:17<00:00,  5.61it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4075, Accuracy: 8590/10000 (85.90%)\n",
      "\n",
      "EPOCH: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.512964129447937 Batch_id=97 Accuracy=83.02: 100%|██████████| 98/98 [00:17<00:00,  5.56it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3972, Accuracy: 8607/10000 (86.07%)\n",
      "\n",
      "EPOCH: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5551376342773438 Batch_id=97 Accuracy=83.45: 100%|██████████| 98/98 [00:17<00:00,  5.64it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4160, Accuracy: 8578/10000 (85.78%)\n",
      "\n",
      "EPOCH: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.4812968075275421 Batch_id=97 Accuracy=83.49: 100%|██████████| 98/98 [00:17<00:00,  5.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4023, Accuracy: 8642/10000 (86.42%)\n",
      "\n",
      "EPOCH: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.41458043456077576 Batch_id=97 Accuracy=83.57: 100%|██████████| 98/98 [00:17<00:00,  5.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4088, Accuracy: 8599/10000 (85.99%)\n",
      "\n",
      "EPOCH: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.4869644045829773 Batch_id=97 Accuracy=83.70: 100%|██████████| 98/98 [00:17<00:00,  5.69it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4286, Accuracy: 8529/10000 (85.29%)\n",
      "\n",
      "EPOCH: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.4444027841091156 Batch_id=97 Accuracy=84.00: 100%|██████████| 98/98 [00:17<00:00,  5.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3960, Accuracy: 8649/10000 (86.49%)\n",
      "\n",
      "EPOCH: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5004456639289856 Batch_id=97 Accuracy=83.99: 100%|██████████| 98/98 [00:17<00:00,  5.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3913, Accuracy: 8673/10000 (86.73%)\n",
      "\n",
      "EPOCH: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5202146172523499 Batch_id=97 Accuracy=84.18: 100%|██████████| 98/98 [00:17<00:00,  5.72it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4127, Accuracy: 8609/10000 (86.09%)\n",
      "\n",
      "EPOCH: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5145465135574341 Batch_id=97 Accuracy=84.26: 100%|██████████| 98/98 [00:17<00:00,  5.65it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4056, Accuracy: 8622/10000 (86.22%)\n",
      "\n",
      "EPOCH: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.44233250617980957 Batch_id=97 Accuracy=84.20: 100%|██████████| 98/98 [00:16<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3900, Accuracy: 8670/10000 (86.70%)\n",
      "\n",
      "EPOCH: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.4462079107761383 Batch_id=97 Accuracy=84.53: 100%|██████████| 98/98 [00:17<00:00,  5.64it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3783, Accuracy: 8712/10000 (87.12%)\n",
      "\n",
      "EPOCH: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.42476850748062134 Batch_id=97 Accuracy=84.85: 100%|██████████| 98/98 [00:17<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3964, Accuracy: 8675/10000 (86.75%)\n",
      "\n",
      "EPOCH: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.4358817934989929 Batch_id=97 Accuracy=84.84: 100%|██████████| 98/98 [00:17<00:00,  5.49it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3883, Accuracy: 8698/10000 (86.98%)\n",
      "\n",
      "EPOCH: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.3639569878578186 Batch_id=97 Accuracy=84.90: 100%|██████████| 98/98 [00:17<00:00,  5.66it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3939, Accuracy: 8666/10000 (86.66%)\n",
      "\n",
      "EPOCH: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.4747036099433899 Batch_id=97 Accuracy=84.92: 100%|██████████| 98/98 [00:17<00:00,  5.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3924, Accuracy: 8676/10000 (86.76%)\n",
      "\n",
      "EPOCH: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.3899494409561157 Batch_id=97 Accuracy=85.10: 100%|██████████| 98/98 [00:17<00:00,  5.67it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3839, Accuracy: 8706/10000 (87.06%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "model =  Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "# scheduler = StepLR(optimizer, step_size=6, gamma=0.1)\n",
    "\n",
    "\n",
    "EPOCHS = 50\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"EPOCH:\", epoch)\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    # scheduler.step()\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
